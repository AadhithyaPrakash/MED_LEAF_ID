{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.feature as feature\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\"\n",
    "output_dir = r\"D:/MED_LEAF_ID-1/preprocessed_glcm\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Allowed image extensions\n",
    "allowed_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "\n",
    "# GLCM Feature Extraction Parameters\n",
    "distances = [1, 2, 3, 4, 5]\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_glcm(image):\n",
    "    \"\"\"\n",
    "    Advanced preprocessing optimized for GLCM feature extraction\n",
    "    \n",
    "    Best Practices:\n",
    "    1. Background Removal\n",
    "    2. Noise Reduction\n",
    "    3. Contrast Enhancement\n",
    "    4. Adaptive Thresholding\n",
    "    5. Texture Preservation\n",
    "    \"\"\"\n",
    "    # Convert to PIL for background removal\n",
    "    pil_image = Image.fromarray(image)\n",
    "    \n",
    "    # Remove background using rembg\n",
    "    output_pil = remove(pil_image)\n",
    "    output_np = np.array(output_pil)\n",
    "    \n",
    "    # Handle RGBA to RGB conversion\n",
    "    if output_np.shape[2] == 4:\n",
    "        output_np = cv2.cvtColor(output_np, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "    # Convert to Grayscale\n",
    "    gray = cv2.cvtColor(output_np, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Advanced Noise Reduction\n",
    "    # 1. Non-local means denoising\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    \n",
    "    # 2. Adaptive Histogram Equalization for contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    \n",
    "    # 3. Adaptive Thresholding\n",
    "    # Prevents over/under-exposure issues\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        enhanced, 255, \n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    # 4. Morphological operations for noise cleanup\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # 5. Edge Enhancement for Texture Preservation\n",
    "    # Gentle edge enhancement to preserve texture details\n",
    "    edges = cv2.Canny(cleaned, 50, 150)\n",
    "    enhanced_texture = cv2.addWeighted(cleaned, 0.8, edges, 0.2, 0)\n",
    "    \n",
    "    return enhanced_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image):\n",
    "    \"\"\"\n",
    "    Extract comprehensive GLCM features for texture analysis\n",
    "    \"\"\"\n",
    "    # Ensure image is 2D and in uint8 format\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    # Normalize the image\n",
    "    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Store feature extraction results\n",
    "    features_list = []\n",
    "    \n",
    "    for d in distances:\n",
    "        for angle in angles:\n",
    "            # Compute GLCM matrix\n",
    "            glcm = feature.graycomatrix(\n",
    "                image, \n",
    "                distances=[d], \n",
    "                angles=[angle], \n",
    "                symmetric=True, \n",
    "                normed=True\n",
    "            )\n",
    "            \n",
    "            # Extract statistical features\n",
    "            contrast = feature.graycoprops(glcm, 'contrast')[0, 0]\n",
    "            energy = feature.graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = feature.graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "            correlation = feature.graycoprops(glcm, 'correlation')[0, 0]\n",
    "            dissimilarity = feature.graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "            asm = feature.graycoprops(glcm, 'ASM')[0, 0]\n",
    "            \n",
    "            # Calculate entropy\n",
    "            entropy = -np.sum(glcm * np.log2(glcm + np.finfo(float).eps))\n",
    "            \n",
    "            features_list.extend([\n",
    "                contrast, energy, homogeneity, \n",
    "                correlation, dissimilarity, asm, entropy\n",
    "            ])\n",
    "    \n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    \"\"\"Process images for comprehensive GLCM feature extraction\"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            if os.path.splitext(filename)[1].lower() in allowed_extensions:\n",
    "                img_path = os.path.join(root, filename)\n",
    "                \n",
    "                # Read image\n",
    "                image = cv2.imread(img_path)\n",
    "                \n",
    "                if image is None:\n",
    "                    print(f\"‚ùå Skipping unreadable image: {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Preprocess for GLCM\n",
    "                preprocessed_img = preprocess_for_glcm(image)\n",
    "                \n",
    "                # Extract class name\n",
    "                class_name = os.path.basename(os.path.dirname(img_path))\n",
    "                \n",
    "                # Extract GLCM features\n",
    "                glcm_features = extract_glcm_features(preprocessed_img)\n",
    "                \n",
    "                # Add class name and filename to features\n",
    "                features_list.append([class_name, filename] + glcm_features)\n",
    "                \n",
    "                # Optional: Save preprocessed image\n",
    "                relative_path = os.path.relpath(img_path, input_dir)\n",
    "                save_path = os.path.join(output_dir, relative_path)\n",
    "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                cv2.imwrite(save_path, preprocessed_img)\n",
    "                \n",
    "                print(f\"‚úÖ Processed: {img_path}\")\n",
    "    \n",
    "    # Prepare DataFrame columns\n",
    "    columns = ['Class_Name', 'Image_Name']\n",
    "    for d in distances:\n",
    "        for angle in angles:\n",
    "            columns += [\n",
    "                f'contrast_d{d}_a{angle}',\n",
    "                f'energy_d{d}_a{angle}',\n",
    "                f'homogeneity_d{d}_a{angle}',\n",
    "                f'correlation_d{d}_a{angle}',\n",
    "                f'dissimilarity_d{d}_a{angle}',\n",
    "                f'asm_d{d}_a{angle}',\n",
    "                f'entropy_d{d}_a{angle}'\n",
    "            ]\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(features_list, columns=columns)\n",
    "    output_file = os.path.join(output_dir, 'glcm_features.csv')\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"üî• GLCM Feature Extraction Completed!\")\n",
    "    print(f\"Features saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\10.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\100.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\102.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\104.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\106.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\108.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\110.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\112.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\114.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\116.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\118.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\12.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\120.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\122.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\124.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\126.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\128.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\130.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\132.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\134.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\136.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\138.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\14.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\140.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\142.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\144.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\146.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\148.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\150.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\152.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\154.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\156.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\158.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\16.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\160.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\162.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\164.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\166.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\168.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\170.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\172.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\174.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\176.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\178.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\18.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\180.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\182.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\184.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\186.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\188.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\190.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\192.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\194.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\196.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\198.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\2.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\20.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\200.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\202.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\204.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\206.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\208.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\210.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\212.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\214.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\216.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\218.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\22.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\220.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\222.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\224.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\226.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\24.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\26.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\260.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\262.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\264.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\266.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\268.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\270.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\272.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\274.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\276.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\278.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\28.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\280.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\282.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\284.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\286.jpg\n",
      "‚úÖ Processed: D:\\MED_LEAF_ID-1\\dataset\\Medicinal Leaf dataset\\Aloevera\\288.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\MED_LEAF_ID\\data\\glcm_features.csv\")\n",
    "\n",
    "# Drop the Image_Name column as it's not needed\n",
    "df = df.drop(columns=[\"Image_Name\"])\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Class_Name\"] = label_encoder.fit_transform(df[\"Class_Name\"])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[\"Class_Name\"])\n",
    "y = df[\"Class_Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(x=y)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Plant Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(X.corr(), cmap=\"coolwarm\", vmax=1.0, vmin=-1.0, square=True)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using Recursive Feature Elimination (RFE)\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(log_reg, n_features_to_select=30)\n",
    "rfe.fit(X, y)\n",
    "X_selected = X.loc[:, rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_selected, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Define parameter grid for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": [50, 100, 200, 300],\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50, cv=5, verbose=1, n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y)), random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators=[('rf', best_rf), ('xgb', xgb_clf)], voting='soft')\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensemble.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters (RF):\", random_search.best_params_)\n",
    "print(\"Ensemble Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the path where the model will be saved\n",
    "model_path = r\"D:\\MED_LEAF_ID\\models\\plant_classifier.pkl\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(ensemble, model_path)\n",
    "\n",
    "print(f\"Model saved successfully at: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
