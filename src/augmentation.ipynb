{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = read_image(img_path).float() / 255.0  # Normalize to [0,1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"D:/MED_LEAF_ID/dataset/Medicinal Leaf dataset\"\n",
    "augmented_directory = \"D:/MED_LEAF_ID/data/augmented\"\n",
    "os.makedirs(augmented_directory, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "TARGET_AUGMENTED_COUNT = 500 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.6.0+cu126\n",
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Current Device: 0\n",
      "CUDA Memory Allocated: 0.0 MB\n",
      "CUDA Memory Reserved: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "print(\"CUDA Memory Allocated:\", torch.cuda.memory_allocated(0) / 1024**2, \"MB\")\n",
    "print(\"CUDA Memory Reserved:\", torch.cuda.memory_reserved(0) / 1024**2, \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a simple model\n",
    "model = torch.nn.Linear(10, 2).to(device)\n",
    "\n",
    "# Create a tensor and move it to GPU\n",
    "x = torch.randn(10).to(device)\n",
    "output = model(x)\n",
    "\n",
    "print(\"Output Device:\", output.device)  # Should print \"cuda:0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Matrix multiplication time on GPU: 0.819808 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create a large tensor and move it to GPU\n",
    "tensor_size = (10000, 10000)\n",
    "t = torch.randn(tensor_size, device=device)\n",
    "\n",
    "# Measure computation time\n",
    "start = time.time()\n",
    "t.matmul(t)\n",
    "torch.cuda.synchronize()  # Ensure all GPU operations finish\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication time on GPU: {end - start:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu126\n",
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Current Device: 0\n",
      "Tensor allocated successfully on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "\n",
    "tensor = torch.randn(10000, 10000, device=\"cuda\")  # Allocate a large tensor on GPU\n",
    "print(\"Tensor allocated successfully on:\", tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Aloevera: 0/500 augmented images present.\n",
      "Processing Amla: 0/500 augmented images present.\n",
      "Processing Amruthaballi: 0/500 augmented images present.\n",
      "Processing Arali: 0/500 augmented images present.\n",
      "Processing ashoka: 0/500 augmented images present.\n",
      "Processing Astma_weed: 0/500 augmented images present.\n",
      "Processing Badipala: 0/500 augmented images present.\n",
      "Processing Balloon_Vine: 0/500 augmented images present.\n",
      "Processing Bamboo: 0/500 augmented images present.\n",
      "Processing Beans: 0/500 augmented images present.\n",
      "Processing Betel: 0/500 augmented images present.\n",
      "Processing Bhrami: 0/500 augmented images present.\n",
      "Processing Bringaraja: 0/500 augmented images present.\n",
      "Processing camphor: 0/500 augmented images present.\n",
      "Processing Caricature: 0/500 augmented images present.\n",
      "Processing Castor: 0/500 augmented images present.\n",
      "Processing Catharanthus: 0/500 augmented images present.\n",
      "Processing Chakte: 0/500 augmented images present.\n",
      "Processing Chilly: 0/500 augmented images present.\n",
      "Processing Citron lime (herelikai): 0/500 augmented images present.\n",
      "Processing Coffee: 0/500 augmented images present.\n",
      "Processing Common rue(naagdalli): 0/500 augmented images present.\n",
      "Processing Coriender: 0/500 augmented images present.\n",
      "Processing Curry: 0/500 augmented images present.\n",
      "Processing Doddpathre: 0/500 augmented images present.\n",
      "Processing Drumstick: 0/500 augmented images present.\n",
      "Processing Ekka: 0/500 augmented images present.\n",
      "Processing Eucalyptus: 0/500 augmented images present.\n",
      "Processing Ganigale: 0/500 augmented images present.\n",
      "Processing Ganike: 0/500 augmented images present.\n",
      "Processing Gasagase: 0/500 augmented images present.\n",
      "Processing Ginger: 0/500 augmented images present.\n",
      "Processing Globe Amarnath: 0/500 augmented images present.\n",
      "Processing Guava: 0/500 augmented images present.\n",
      "Processing Henna: 0/500 augmented images present.\n",
      "Processing Hibiscus: 0/500 augmented images present.\n",
      "Processing Honge: 0/500 augmented images present.\n",
      "Processing Insulin: 0/500 augmented images present.\n",
      "Processing Jackfruit: 0/500 augmented images present.\n",
      "Processing Jasmine: 0/500 augmented images present.\n",
      "Processing kamakasturi: 0/500 augmented images present.\n",
      "Processing Kambajala: 0/500 augmented images present.\n",
      "Processing Kasambruga: 0/500 augmented images present.\n",
      "Processing kepala: 0/500 augmented images present.\n",
      "Processing Kohlrabi: 0/500 augmented images present.\n",
      "Processing Lantana: 0/500 augmented images present.\n",
      "Processing Lemon: 0/500 augmented images present.\n",
      "Processing Lemongrass: 0/500 augmented images present.\n",
      "Processing Malabar_Nut: 0/500 augmented images present.\n",
      "Processing Malabar_Spinach: 0/500 augmented images present.\n",
      "Processing Mango: 0/500 augmented images present.\n",
      "Processing Marigold: 0/500 augmented images present.\n",
      "Processing Mint: 0/500 augmented images present.\n",
      "Processing Neem: 0/500 augmented images present.\n",
      "Processing Nelavembu: 0/500 augmented images present.\n",
      "Processing Nerale: 0/500 augmented images present.\n",
      "Processing Nooni: 0/500 augmented images present.\n",
      "Processing Onion: 0/500 augmented images present.\n",
      "Processing Padri: 0/500 augmented images present.\n",
      "Processing Palak(Spinach): 0/500 augmented images present.\n",
      "Processing Papaya: 0/500 augmented images present.\n",
      "Processing Parijatha: 0/500 augmented images present.\n",
      "Processing Pea: 0/500 augmented images present.\n",
      "Processing Pepper: 0/500 augmented images present.\n",
      "Processing Pomoegranate: 0/500 augmented images present.\n",
      "Processing Pumpkin: 0/500 augmented images present.\n",
      "Processing Raddish: 0/500 augmented images present.\n",
      "Processing Rose: 0/500 augmented images present.\n",
      "Processing Sampige: 0/500 augmented images present.\n",
      "Processing Sapota: 0/500 augmented images present.\n",
      "Processing Seethaashoka: 0/500 augmented images present.\n",
      "Processing Seethapala: 0/500 augmented images present.\n",
      "Processing Spinach1: 0/500 augmented images present.\n",
      "Processing Tamarind: 0/500 augmented images present.\n",
      "Processing Taro: 0/500 augmented images present.\n",
      "Processing Tecoma: 0/500 augmented images present.\n",
      "Processing Thumbe: 0/500 augmented images present.\n",
      "Processing Tomato: 0/500 augmented images present.\n",
      "Processing Tulsi: 0/500 augmented images present.\n",
      "Processing Turmeric: 0/500 augmented images present.\n",
      "Augmentation completed with PyTorch and GPU acceleration.\n"
     ]
    }
   ],
   "source": [
    "for plant_name in os.listdir(source_directory):\n",
    "    class_folder = os.path.join(source_directory, plant_name)\n",
    "    augmented_class_folder = os.path.join(augmented_directory, plant_name)\n",
    "    os.makedirs(augmented_class_folder, exist_ok=True)\n",
    "\n",
    "    existing_augmented_count = len([f for f in os.listdir(augmented_class_folder) if f.startswith(\"aug_\")])\n",
    "    if existing_augmented_count >= TARGET_AUGMENTED_COUNT:\n",
    "        print(f\"Skipping {plant_name}, already has {existing_augmented_count} augmented images.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {plant_name}: {existing_augmented_count}/{TARGET_AUGMENTED_COUNT} augmented images present.\")\n",
    "    images_needed = TARGET_AUGMENTED_COUNT - existing_augmented_count\n",
    "\n",
    "    image_paths = [os.path.join(class_folder, img) for img in os.listdir(class_folder) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    dataset = CustomImageDataset(image_paths, transform=transform)  # Apply transform here\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    i = existing_augmented_count \n",
    "    for img_tensor, img_path in dataloader:\n",
    "        img_tensor = img_tensor.to(device)  \n",
    "        augmented_img = transform(img_tensor)  \n",
    "\n",
    "        save_image(augmented_img.cpu(), os.path.join(augmented_class_folder, f\"aug_{i}.png\")) \n",
    "        i += 1\n",
    "        if i >= TARGET_AUGMENTED_COUNT:\n",
    "            break\n",
    "\n",
    "print(\"Augmentation completed with PyTorch and GPU acceleration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sample_img, _ = \u001b[43mdataset\u001b[49m[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# Get an image from dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.imshow(sample_img.permute(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m).numpy())  \u001b[38;5;66;03m# Convert tensor to image\u001b[39;00m\n\u001b[32m      4\u001b[39m plt.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample_img, _ = dataset[0]  # Get an image from dataset\n",
    "plt.imshow(sample_img.permute(1, 2, 0).numpy())  # Convert tensor to image\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
